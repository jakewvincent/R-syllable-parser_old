---
title: "Transcription and syllables"
output: html_notebook
---

```{r libraries}
library(magrittr)
library(dplyr)
library(ggplot2)
library(stringr)
library(tidyr)

# Define functions that work like RIGHT and LEFT in excel
right = function(text, n_char) {
  substr(text, nchar(text) - n_char + 1, nchar(text))
}
left = function(text, n_char) {
  substr(text, 1, n_char)
}

# Modify default print rule
# NOTE: REQUIRES CHANGING THE CLASS OF ANY DF W/ UNICODE IN IT. FOR EXAMPLE:
#       class(d) <- c("unicode_df", "data.frame") 

# this is print.default from base R with only two lines modified, see #old# 
print.unicode_df <- function (x, ..., digits = NULL, quote = FALSE, right   
= TRUE, 
     row.names = TRUE) 
{ 
     n <- length(row.names(x)) 
     if (length(x) == 0L) { 
         cat(sprintf(ngettext(n, "data frame with 0 columns and %d row", 
             "data frame with 0 columns and %d rows", domain = "R-base"), 
             n), "\n", sep = "") 
     } 
     else if (n == 0L) { 
         print.default(names(x), quote = FALSE) 
         cat(gettext("<0 rows> (or 0-length row.names)\n")) 
     } 
     else { 
         #old# m <- as.matrix(format.data.frame(x, digits = digits, 
         #old#     na.encode = FALSE)) 
         m <- as.matrix(x) 
         if (!isTRUE(row.names)) 
             dimnames(m)[[1L]] <- if (identical(row.names, FALSE)) 
                 rep.int("", n) 
             else row.names 
         print(m, ..., quote = quote, right = right) 
     } 
     invisible(x) 
} 

```

Get pronunciations from the Carnegie Mellon University (CMU) Pronouncing Dictionary [here](http://svn.code.sf.net/p/cmusphinx/code/trunk/cmudict/cmudict-0.7b) and save as a csv file. Remove the first commented out lines, save, import into excel appropriately, and re-save as a csv file.

```{r read.dictionary}
# Read in the CMU Pronouncing Dictionary (pronunciations in arpabet)
cmudictarpa <- read.table(file = "cmudict-0.7b.txt",
                          colClasses = "character",
                          header = FALSE,
                          sep = ",",
                          fill = TRUE,
                          quote = "\"")

# Make column names
x <- 1
for(n in 1:ncol(cmudictarpa)){
  if(x == 1){
    colnames(cmudictarpa)[x] <- "word"
    x <- x+1
  } else {
    colnames(cmudictarpa)[x] <- paste("segment", x-1, sep = "")
    x <- x+1
  }
}
```

```{r stress}
# I want to add columns to indicate which segment has primary or secondary stress.
# To know how many columns to add, let's find out the maximum number of times a word in the dictionary can bear primary stress or secondary stress.
# Make a matrix to save this info in
stress.freq <- matrix(nrow = nrow(cmudictarpa), ncol = 3)
for (row in 1:nrow(cmudictarpa)) {
  stress.freq[row,1] <- paste(cmudictarpa[row,2:ncol(cmudictarpa)], collapse = "")
}
colnames(stress.freq) <- c("stresses", "primary.count", "secondary.count")

# Count number of 1's (primary stresses) and 2's (secondary stresses) in the collapsed string
for (row in 1:nrow(stress.freq)) {
   str_count(stress.freq[row,1], pattern = "1") -> stress.freq[row,2]
   str_count(stress.freq[row,1], pattern = "2") -> stress.freq[row,3]
}

stress.freq %>% as.data.frame -> stress.freq

# What's the maximum number of primary stresses?
stress.freq[,2] %>% as.numeric %>% max-1 -> max.prim

# What's the maximum number of secondary stresses?
stress.freq[,3] %>% as.numeric %>% max-1 -> max.sec

# Add columns for max number of primary stresses
for (n in 1:max.prim) {
  eval(parse(text = paste("mutate(cmudictarpa, pri.stress", n, " = NA)", sep = ""))) -> cmudictarpa
}

# Add columns for max number of secondary stresses
for (n in 1:max.sec) {
  eval(parse(text = paste("mutate(cmudictarpa, sec.stress", n, " = NA)", sep = ""))) -> cmudictarpa
}
```

```{r extract_stress}
# Extract stress information and remove stress information from the segments
# For each primary stress, copy the segment with primary stress to its own column in that row.
# For each secondary stress, copy the segment w/ secondary stress to its own column in that row.
for (row in 1:nrow(cmudictarpa)) {
  nthprimary <- 1
  nthsecondary <- 1
  w <- length(colnames(cmudictarpa)[left(colnames(cmudictarpa), 3)=="seg"|left(colnames(cmudictarpa), 4)=="word"])
  x <- length(colnames(cmudictarpa))-length(colnames(cmudictarpa)[left(colnames(cmudictarpa), 3)=="sec"])
  for (segment in 2:w) {
    if (right(cmudictarpa[row,segment],1)==1) {
      # Copy the column name to the row corresponding to the nth primary stress
      colnames(cmudictarpa)[segment] -> cmudictarpa[row,w+nthprimary]
      # Increase the counter by 1
      nthprimary <- nthprimary + 1
    } else {
      if (right(cmudictarpa[row,segment],1)==2) {
        # Copy the column name to the row corresponding to the nth secondary stress
        colnames(cmudictarpa)[segment] -> cmudictarpa[row,x+nthsecondary]
        # Increase the counter by 1
        nthsecondary <- nthsecondary + 1
      }
    }
  }
}
```

```{r unique, options}
# Save a version to replace arpabet strings w/ IPA characters
cmudictipa <- cmudictarpa

# Get a list of all the segments in the arpabet
arpa.segments <- NA
for (segment in 2:w) {
  arpa.segments <- c(arpa.segments, unique(cmudictarpa[,segment]))
}
arpa.segments <- sort(unique(arpa.segments))
print(arpa.segments)
```

```{r ipa_version}
# Convert arpabet segments to IPA characters
for (col in 2:w) {
  str_replace_all(cmudictipa[,col], c("AA0" = "ɑ",
                                      "AA1" = "ɑ",
                                      "AA2" = "ɑ",
                                      "AE0" = "æ",
                                      "AE1" = "æ",
                                      "AE2" = "æ",
                                      "AH0" = "ə",
                                      "AH1" = "ʌ",
                                      "AH2" = "ʌ",
                                      "AO0" = "ɔ",
                                      "AO1" = "ɔ",
                                      "AO2" = "ɔ",
                                      "AW0" = "aʊ",
                                      "AW1" = "aʊ",
                                      "AW2" = "aʊ",
                                      "AY0" = "aɪ",
                                      "AY1" = "aɪ",
                                      "AY2" = "aɪ",
                                      "B" = "b",
                                      "CH" = "ʧ",
                                      "DH" = "ð",
                                      "D" = "d",
                                      "EH0" = "ɛ",
                                      "EH1" = "ɛ",
                                      "EH2" = "ɛ",
                                      "ER0" = "ɚ",
                                      "ER1" = "ɚ",
                                      "ER2" = "ɚ",
                                      "EY0" = "eɪ",
                                      "EY1" = "eɪ",
                                      "EY2" = "eɪ",
                                      "F" = "f",
                                      "HH" = "h",
                                      "IH0" = "ɪ",
                                      "IH1" = "ɪ",
                                      "IH2" = "ɪ",
                                      "IY0" = "i",
                                      "IY1" = "i",
                                      "IY2" = "i",
                                      "JH" = "ʤ",
                                      "K" = "k",
                                      "L" = "l",
                                      "M" = "m",
                                      "NG" = "ŋ",
                                      "G" = "g",
                                      "N" = "n",
                                      "OW0" = "oʊ",
                                      "OW1" = "oʊ",
                                      "OW2" = "oʊ",
                                      "OY0" = "ɔɪ",
                                      "OY1" = "ɔɪ",
                                      "OY2" = "ɔɪ",
                                      "P" = "p",
                                      "R" = "ɹ",
                                      "SH" = "ʃ",
                                      "S" = "s",
                                      "TH" = "θ",
                                      "T" = "t",
                                      "UH0" = "ʊ",
                                      "UH1" = "ʊ",
                                      "UH2" = "ʊ",
                                      "UW0" = "u",
                                      "UW1" = "u",
                                      "UW2" = "u",
                                      "V" = "v",
                                      "W" = "w",
                                      "Y" = "j",
                                      "ZH" = "ʒ",
                                      "Z" = "z")) -> cmudictipa[,col]
}

# make words lowercase
cmudictipa$word <- tolower(cmudictipa$word)

# make column for whole transcription
cmudictipa %>% mutate(transcription = paste(cmudictipa$segment1,
                           cmudictipa$segment2,
                           cmudictipa$segment3,
                           cmudictipa$segment4,
                           cmudictipa$segment5,
                           cmudictipa$segment6,
                           cmudictipa$segment7,
                           cmudictipa$segment8,
                           cmudictipa$segment9,
                           cmudictipa$segment10,
                           cmudictipa$segment11,
                           cmudictipa$segment12,
                           cmudictipa$segment13,
                           cmudictipa$segment14,
                           cmudictipa$segment15,
                           cmudictipa$segment16,
                           cmudictipa$segment17,
                           cmudictipa$segment18,
                           cmudictipa$segment19,
                           cmudictipa$segment20,
                           cmudictipa$segment21,
                           cmudictipa$segment22,
                           cmudictipa$segment23,
                           cmudictipa$segment24,
                           cmudictipa$segment25,
                           cmudictipa$segment26,
                           cmudictipa$segment27,
                           cmudictipa$segment28,
                           cmudictipa$segment29,
                           cmudictipa$segment30,
                           cmudictipa$segment31,
                           cmudictipa$segment32,
                           sep = "")) -> cmudictipa
```

```{r transcribe_function}
transcribe <- function(text) {
  subset(cmudictipa, word == text, select = transcription)[1,1] -> transcribed
  return(transcribed)
}
```

```{r clean_up}
# Clean up the dfs

# Make the unicode visible when printing
class(cmudictipa) <- c("unicode_df", "data.frame")

# Move the "transcription" column to be adjacent to the "word" column
cmudictipa <- cmudictipa[,c(1, 45, 2:44)]

# Write to a text file
cmudictipa %>% subset(select = c(word, transcription, CV_string)) %>% droplevels %>% write.csv(., file = "cmu_dictionary_ipa.txt", fileEncoding = "UTF-8")

write.csv(cmudictipa[,c(1, 2, 46)], file = "cmu_dictionary_ipa2", fileEncoding = "UTF-8")
```

```{r features, options}
features <- data.frame(segment = c("i", "y", "ɨ", "ʉ", "ɯ", "u", "ɪ", "ʏ", "ʊ", "e", "ø", "ɘ", "ɵ", "ɤ",
                                   "o", "ɛ", "œ", "ə", "ɞ", "ʌ", "ɔ", "æ", "ɶ", "a", "ɑ", "ɒ", "j", "ʋ",
                                   "ɥ", "w", "ʙ", "l", "r", "ɾ", "ɹ", "ʎ", "ʟ", "ʀ", "m", "ɱ", "n", "ɳ",
                                   "ɲ", "ŋ", "ɴ", "p", "b", "ɸ", "β", "f", "v", "θ", "ð", "t", "d", "s",
                                   "z", "ʃ", "ʒ", "ʦ", "ʣ", "ʧ", "ʤ", "c", "ɟ", "ç", "ʝ", "k", "g", "x",
                                   "ɣ", "q", "ɢ", "χ", "ʁ", "\u0127", "ʕ", "h", "ɦ", "ʔ", "ɚ"),
                       syllabic = c(rep(1, 26), rep(0, 54), 1),
                       consonantal = c(rep(0, 30), rep(1, 47), rep(0, 2), 1, 0),
                       approximant = c(rep(1, 38), rep(0, 42), 1),
                       sonorant = c(rep(1, 45), rep(0, 35), 1),
                       nasal = c(rep(0, 38), rep(1, 7), rep(0, 35), 0),
                       continuant = c(rep(1, 38), rep(0, 9), rep(1, 6), rep(0, 2), rep(1, 4), rep(0, 6),
                                      rep(1, 2), rep(0, 2), rep(1, 2), rep(0, 2), rep(1, 6), 0, 1),
                       delrel = c(rep(NA, 45), rep(0, 2), rep(1, 6), rep(0, 2), rep(1, 8),
                                          rep(0, 2), rep(1, 2), rep(0, 2), rep(1, 2), rep(0, 2),
                                          rep(1, 6), 0, NA),
                       trill = c(rep(0, 30), 1, 0, 1, rep(0, 4), 1, rep(0, 42), 0),
                       tap = c(rep(0, 33), 1, rep(0, 46), 0),
                       voice = c(rep(1, 45), rep(c(0, 1), 17), 0, 1),
                       sprgl = c(rep(0, 77), 1, 1, rep(0, 2)),
                       constrgl = c(rep(0, 79), 1, 0),
                       labial = c(rep(c(0, 1), 4), rep(c(1, 0), 8), rep(c(0, 1), 2), rep(1, 3),
                                  rep(0, 7), rep(1, 2), rep(0, 5), rep(1, 6), rep(0, 30)),
                       round = c(rep(c(0, 1), 4), rep(c(1, 0), 8), 0, 1, rep(0, 2), rep(1, 2), rep(0, 51)),
                       labiodental = c(rep(0, 27), 1, rep(0, 11), 1, rep(0, 9), rep(1, 2), rep(0, 30)),
                       coronal = c(rep(0, 31), rep(1, 5), rep(0, 4), rep(1, 3), rep(0, 8), rep(1, 16),
                                   rep(0, 13), 1),
                       anterior = c(rep(NA, 31), rep(1, 3), rep(0, 2), rep(NA, 4), 1, rep(0, 2),
                                    rep(NA, 8), rep(1, 6), rep(0, 2), rep(1, 2), rep(0, 6), rep(NA, 13), 1),
                       distributed = c(rep(NA, 31), rep(0, 3), rep(1, 2), rep(NA, 4), rep(0, 2), 1,
                                       rep(NA, 8), rep(1, 2), rep(0, 4), rep(1, 2), rep(0, 2), rep(1, 6),
                                       rep(NA, 13), 1),
                       strident = c(rep(NA, 31), rep(0, 5), rep(NA, 4), rep(0, 3), rep(NA, 8), rep(0, 4),
                                    rep(1, 8), rep(0, 4), rep(NA, 13), 0),
                       lateral = c(rep(NA, 26), rep(0, 5), 1, rep(0, 3), rep(1, 2), rep(0, 44)),
                       dorsal = c(rep(1, 27), 0, rep(1, 2), rep(0, 5), rep(1, 3), rep(0, 4), rep(1, 3),
                                  rep(0, 18), rep(1, 14), rep(0, 3), 1),
                       high = c(rep(1, 9), rep(0, 17), 1, NA, rep(1, 2), rep(NA, 5), rep(1, 2), 0,
                                rep(NA, 4), rep(1, 2), 0, rep(NA, 18), rep(1, 8), rep(0, 6), rep(NA, 3), 0),
                       low = c(rep(0, 21), rep(1, 5), 0, NA, rep(0, 2), rep(NA, 5), rep(0, 3), rep(NA, 4),
                               rep(0, 3), rep(NA, 18), rep(0, 12), rep(1, 2), rep(NA, 3), 0),
                       front = c(rep(1, 2), rep(0, 4), rep(1, 2), 0, rep(1, 2), rep(0, 4), rep(1, 2),
                                 rep(0, 4), rep(1, 2), rep(0, 3), 1, NA, 1, 0, rep(NA, 5), 1, NA, 0,
                                 rep(NA, 4), 1, NA, 0, rep(NA, 18), rep(1, 4), rep(0, 10), rep(NA, 3), 0),
                       back = c(rep(0, 4), rep(1, 2), rep(0, 2), 1, rep(0, 4), rep(1, 2), rep(0, 4),
                                rep(1, 2), rep(0, 3), rep(1, 2), 0, NA, 0, 1, rep(NA, 5), 0, NA, 1,
                                rep(NA, 4), 0, NA, 1, rep(NA, 18), rep(0, 8), rep(1, 6), rep(NA, 3), 0),
                       tense = c(rep(1, 6), rep(0, 3), rep(1, 6), rep(0, 6), rep(NA, 5), 1, NA, rep(1, 2),
                                 rep(NA, 50), 0))

# Add sonority as a column, where the sonority levels are represented by numbers from 1-6
# 1 = stops, 2 = fricatives, 3 = nasals, 4 = liquids, 5 = glides, 6 = vowels
features %>%
  mutate(sonority = ifelse(syllabic == "1", "6",
                           ifelse(syllabic == "0" &
                                    consonantal == "0" &
                                    approximant == "1" &
                                    sonorant == "1", "5",
                                  ifelse(syllabic == "0" &
                                           consonantal == "1" &
                                           approximant == "1" &
                                           sonorant == "1", "4",
                                         ifelse(nasal == "1", "3",
                                                ifelse(sonorant == "0" &
                                                         continuant == "1", "2",
                                                       ifelse(sonorant == "0" &
                                                                continuant == "0", "1", ""))))))) -> features
# Move sonority to be second column
features <- features[,c(1, 28, 2:27)]

class(features) <- c("unicode_df", "data.frame")
```

```{r CV_and_sonority_functions}
# Define a function that converts a string of IPA characters into a string of Cs and Vs
cvify <- function(text) {
  if (NA %in% text) {
    warning("Input contains NA(s), which I don't know how to CVify!")
    return(0)
  } else {
    text <- as.character(text)
    if (length(text) > 1) {
      CVs <- NA
      for (word in 1:length(text)) {
        split_text <- unlist(strsplit(text[word], split = ""))
        split_text_tbl <- matrix(split_text)
        CV_string <- NA
        for (segment in 1:length(split_text_tbl[,1])) {
          features[which(features[,"segment"] == split_text_tbl[segment,1]), "syllabic"] -> syllabic
          ifelse(syllabic == "1", "V", "C") -> CV_string[segment]
        }
        CVified_tbl <- cbind(split_text_tbl, CV_string)
        paste(CVified_tbl[,2], collapse = "") -> CVs[word]
      }
    } else {
      split_text <- unlist(strsplit(text, split = ""))
      matrix(split_text) -> split_text_tbl
      CV_string <- NA
      for (segment in 1:length(split_text_tbl[,1])) {
        features[which(features[,"segment"] == split_text_tbl[segment,1]), "syllabic"] -> syllabic
        ifelse(syllabic == "1", "V", "C") -> CV_string[segment]
      }
      CVified_tbl <- cbind(split_text_tbl, CV_string)
      paste(CVified_tbl[,2], collapse = "") -> CVs
    }
    return(CVs)
  }
}

sonority <- function(text){
  text <- as.character(text)
    if (length(text) > 1) {
    s_levels <- NA
    for (word in 1:length(text)) {
      split_text <- unlist(strsplit(text[word], split = ""))
      split_text_tbl <- matrix(split_text)
      son_string <- NA
      for (seg in 1:length(split_text_tbl[,1])) {
        features[which(features[,"segment"] == split_text_tbl[seg,1]), "sonority"] -> son_string[seg]
      }
      sonified_tbl <- cbind(split_text_tbl, son_string)
      paste(sonified_tbl[,2], collapse = "") -> s_levels[word]
    }
  } else {
  split_text <- unlist(strsplit(text, split = ""))
  matrix(split_text) -> split_text_tbl
  son_string <- NA
  for (seg in 1:length(split_text_tbl[,1])) {
    features[which(features[,"segment"] == split_text_tbl[seg,1]), "sonority"] -> son_string[seg]
  }
  sonified_tbl <- cbind(split_text_tbl, son_string)
  paste(sonified_tbl[,2], collapse = "") -> s_levels
  }
  return(s_levels)
}
```

```{r CVify}
# Add a column into cmudictipa that abstracts into consonants and vowels
suppressWarnings(cmudictipa$CV_string <- cvify(cmudictipa$transcription))
```

```{r licit_onsets}
# Make a list of the licit onset clusters in English, as determined by the ones that are attested word-initially
cmudictipa %>%
  subset(left(CV_string, 3) == "CCV",
         select = transcription) -> CC_words

left(CC_words$transcription, 2) %>% as.data.frame -> CC_clusters
colnames(CC_clusters) <- "CC"
CC_clusters$total <- length(CC_clusters$CC)

# Get some stats on the clusters
CC_clusters %>%
  group_by(as.factor(CC)) %>%
  summarize(n = n(),
            total = mean(total),
            proportion = n/total) -> CC_cluster_stats

# Rename column
colnames(CC_cluster_stats)[1] <- "CC"

# Get a list of licit CC onsets. To try to weed out those that are in this list b/c of borrowed words, starting by assuming that a word-initial CC cluster needs to occur in the cmudictionary at least 20 times to be native.
CC_cluster_stats %>%
  subset(n >= 20) %>%
  .$CC -> CC_native
```

```{r syllabify_function_v0.1}
syllabify_v0.1 <- function(text) {
  # Make a df to store syllabification info
  syllabification <- data.frame(NA, NA, NA, NA)
  # Assign colnames
  colnames(syllabification) <- c("word", "CV_seq", "son_seq", "vowel_pos")
  # Give df the unicode_df class so it's printed correctly
  class(syllabification) <- c("unicode_df", "data.frame")
  # Syllabify each word in the input, adding its information to each row
  for (word in 1:length(text)) {
    # Add that word and CV sequence info and sonority info to the first row of the df
    syllabification[word,1:3] <- c(text[word],
                                   cvify(text[word]),
                                   sonority(text[word]))
    # Get the positions (indices) of the vowels in the word, collapse into a string, and put in table
    vowels <- which(unlist(strsplit(as.character(syllabification[word,"son_seq"]), split = "")) == 6)
    n_sylls <- length(vowels)
    vowel_pos <- paste(vowels, collapse = ", ")
    syllabification[word,"vowel_pos"] <- vowel_pos
    
    # Perform first-pass syllabification, putting any consonants possible into onsets (Parse > Onset > NoCoda)
        # Make an object that will store the position of the last vowel parsed. start w/ 0.
        last <- 0
        # Split up the word into a vector, where each character has a slot in the vector
        split_word <- unlist(strsplit(text[word], split = ""))
    for (syllable in 1:n_sylls) {
      # Get all the segments up to the vowel, collapse them, and store them in the df as a syllable
      syllabification[word, (4+syllable)] <- paste(split_word[(last+1):vowels[syllable]], collapse = "")
      # Save the linear string position of the last vowel in the word that was parsed into a syllable
      last <- vowels[syllable]
      # If we're at the last syllable, ...
      if (syllable == n_sylls) {
        # And if there's something after the vowel (i.e. the pos'n of last vowel ≠ length of word), ...
        if (vowels[syllable] != length(split_word)) {
          # Then tack the remaining stuff onto the end of the last syllable
          syllabification[word, 4+syllable] <- paste(c(syllabification[word, 4+syllable], split_word[(last+1):length(split_word)]), collapse = "")
        }
      }
    }
  }
  # Label the syllable columns
  colnames(syllabification)[5:length(colnames(syllabification))] <- paste("\u03C3", seq_along(5:length(colnames(syllabification))), sep = "")
  return(syllabification)
}
```

```{r syllabify_function_v0.2}
# Parse by indexing linear string, using onsets found in the cmu dictionary
# Parse stepwise by nucleus, onset, and coda; identifying dipththongs as a single nucleus
syllabify_v0.2 <- function(input, diphthong_list, onset_list) {
  
  # Required packages
  require(stringr)
  
  # If diphthongs aren't specified, set it to American English diphthongs
  if (missing(diphthong_list)) {
    diphthong_list <- c("aɪ", "aʊ", "eɪ", "oʊ", "ɔɪ")
    #warning("No diphthongs provided. Using Standard American English diphthongs.")
  }

  # If licit onsets not supplied, use this list
  if (missing(onset_list)) {
    onset_list <- c("ʃɹ", "θɹ", "bɹ", "bj", "bl", "dɹ", "dw", "fɹ",
                    "fj", "fl", "gɹ", "gl", "gw", "hj", "hw", "kɹ",
                    "kj", "kl", "kw", "mj", "pɹ", "pj", "pl", "sk",
                    "sl", "sm", "sn", "sp", "st", "sw", "tɹ", "tw")
    # Removed: ʃl, ʃm, ʃn, ʃw, bw (two bilabials), dj, gj, sv, ts, 
  }
  
  # Make a df to store syllabification info
  syllabification <- data.frame(NA)
  
  # Assign colnames
  colnames(syllabification) <- "input"
  
  # Give the df the unicode_df class so it's printed correctly
  class(syllabification) <- c("unicode_df",
                              "data.frame")
  
  # Syllabify each word in the input, adding its information to each row
  for (word in 1:length(input)) {
    # Add the word to the df
    syllabification[word, 1] <- input[word]
    
    # Index ea segment by splitting word into component chars & associating ea w/ a # corresponding to its string-linear position
    split_word <- unlist(strsplit(as.character(input[word]), split = ""))
    char_index <- as.data.frame(as.matrix(split_word))
    class(char_index) <- c("unicode_df",
                           "data.frame")
    colnames(char_index)[1] <- "segment"
    char_index[,"position"] <- 1:length(split_word)
    char_index[,"sonority"] <- sonority(split_word)
    char_index[,"parsed"] <- FALSE
    char_index[,"syllable"] <- 0
    
    ### Determine syllable nuclei ###
    # Extract vowels
    vowels <- subset(char_index,
                     cvify(segment) == "V")
    
    # Get adjacent vowels (if there is more than one vowel in the word) & determine if they're diphthongs
    if (length(vowels$segment) > 1){
      ## Make a df to store each sequence of two vowels
      vowel_bigrams <- as.data.frame(matrix(ncol = 2))
      ## Set x to 1; each time the loop runs it will be increased by one so that the next bigram can be extracted
      x <- 1
      ## Get positions in linear string of original word of bigrams of extracted vowels
      for (vowel in 1:nrow(vowels)) {
        # If we didn't just parse the last vowel (if x is not equal to the number of vowels in the word), ...
        if (x != nrow(vowels)) {
          # ...then get the positions of those vowels and put in the vowel_bigram df
          vowel_bigrams[vowel,] <- vowels[x:(x+1),"position"]
          x <- x+1
        }
      }
      ## Get the diffs btw the pos'ns in the linear str to see which vowels were adjacent to each other in the original word
      vowel_bigrams$diff <- vowel_bigrams[,2] - vowel_bigrams[,1]
      ## If any vowels have a position difference of 1 (were actually adjacent to each other in the original string), subset only to them
      if (1 %in% vowel_bigrams$diff){
        ## Subset to originally adjacent vowels
        adjacent_vowels <- subset(vowel_bigrams,
                                  diff == 1)
		    class(adjacent_vowels) <- c("unicode_df",
		                                "data.frame")
        ## Extract the adjacent vowels using their positions & paste them together in a new column
        for (pair in 1:nrow(adjacent_vowels)) {
          adjacent_vowels[pair,"bigram"] <- paste(as.character(char_index[,"segment"][adjacent_vowels[pair,1]]),
                                                  as.character(char_index[,"segment"][adjacent_vowels[pair,2]]),
                                                  sep = "")
        }
        ## See if any of these bigrams match the known diphthongs & indicate in adjacent_vowels w/ TRUE or FALSE
        for (bigram in 1:nrow(adjacent_vowels)) {
          # If the bigram is in the list of diphthongs, mark it as TRUE
          if(adjacent_vowels[bigram,"bigram"] %in% diphthong_list){
            adjacent_vowels[bigram,"diphthong"] <- TRUE
          } else {
            # Otherwise, mark it as false
            adjacent_vowels[bigram,"diphthong"] <- FALSE
          }
        }
        # Save the bigrams that are recognized diphthongs if there are any
        if (TRUE %in% adjacent_vowels$diphthong){
          diphthongs <- droplevels(subset(adjacent_vowels,
                                          diphthong == TRUE))
		      class(diphthongs) <- c("unicode_df",
		                             "data.frame")
        }
      }
    }
    
    # Add column to vowel df that says whether the vowel is part of a diphthong (TRUE) or monophthong (FALSE), and if it is part of a diphthong, which diphthong it's a part of (by which row in the diphthongs df it's in)
    for (vowel in 1:nrow(vowels)) {
      if (exists("diphthongs")) {
        if (vowels$position[vowel] %in% as.character(as.matrix(diphthongs[,1:2]))) {
        vowels[vowel,"in.diphthong"] <- TRUE
        vowels[vowel,"which.diphthong"] <- row(diphthongs[,1:2])[which(diphthongs[,1:2] == vowels$position[vowel])]
        } else {
          vowels[vowel,"in.diphthong"] <- FALSE
          # If the vowel isn't part of a diphthong, set "which.diphthong" to 0. Anything that's an actual diphthong will never be assigned zero since row numbers (in the diphthongs df) start w/ 1. Needs to be 0 b/c otherwise it's NA, in which case an error is returned when testing if two vowel characters are part of the same diphthong.
          vowels[vowel,"which.diphthong"] <- 0
        }
      } else {
        vowels[vowel,"in.diphthong"] <- FALSE
        # If the vowel isn't part of a diphthong, set "which.diphthong" to 0. Anything that's an actual diphthong will never be assigned zero since row numbers (in the diphthongs df) start w/ 1. Needs to be 0 b/c otherwise it's NA, in which case an error is returned when testing if two vowel characters are part of the same diphthong.
        vowels[vowel,"which.diphthong"] <- 0
      }
    }
    
    # We now have enough information to say which vowel segments are associated w/ which syllables
    # Cycle through the vowel df and create a vector for the syllable nuclei in this word
    nuclei <- NA
    x <- 1
    for (vowel in 1:nrow(vowels)) {
      # If the vowel is not part of a diphthong, add it to the list of nuclei
      if (vowels[vowel,"in.diphthong"] == FALSE) {
        nuclei[x] <- as.character(vowels[vowel,"segment"])
        # Change parsed status to TRUE
        char_index[vowels[vowel,"position"],]$parsed <- TRUE
        # Indicate which syllable this vowel was parsed into
        char_index[vowels[vowel,"position"],]$syllable <- paste(c("\u03C3.", x),
                                                                collapse = "")
        # Add one to the syllable counter
        x <- x+1
      } else {
        # If we're not at the last vowel in vowels and the vowel and the following vowel are part of a diphthong together, paste them together as the next nucleus
        if (vowel != nrow(vowels)) {
          if (vowels[vowel,"which.diphthong"] > 0 & vowels[vowel,"which.diphthong"] == vowels[vowel+1,"which.diphthong"]) {
          nuclei[x] <- paste(as.character(vowels[vowel:(vowel+1),"segment"]),
                             collapse = "")
          # Change parsed status for both vowels to TRUE
          char_index[vowels[vowel,"position"],]$parsed <- TRUE
          char_index[vowels[vowel,"position"]+1,]$parsed <- TRUE
          # Indicate which syllable this vowel and the following vowel was parsed into
          char_index[vowels[vowel,"position"],]$syllable <- paste(c("\u03C3.", x),
                                                                  collapse = "")
          char_index[vowels[vowel,"position"]+1,]$syllable <- paste(c("\u03C3.", x),
                                                                    collapse = "")
          x <- x+1
        }
        }
      }
    }
    
    # Add nuclei to syllabification table for current word
    for (nucleus in 1:length(nuclei)) {
      syllabification[word,paste(c("\u03C3", nucleus),
                                 collapse = ".")] <- as.character(nuclei[nucleus])
    }
    
    # Remove vowel-related objects (IMPORTANT; this can screw up the next word if more than one word is supplied to the function)
    if (exists("vowel_bigrams")) {
      rm(vowel_bigrams)
    }
    if (exists("adjacent_vowels")) {
      rm(adjacent_vowels)
    }
    if (exists("diphthongs")){
      rm(diphthongs)
    }
    
    message("Step 1: Identify syllable nuclei: ",
            paste(syllabification[,2:ncol(syllabification)],
                  collapse = ", "))
    
    
    
    ### Parse onsets ###
    # For each unparsed consonant in the character index, starting from the end of the word, ...
    for (consonant in rev(subset(char_index, parsed == FALSE)$position)) {
      # If the consonant is preceding the first vowel, parse it into the first syllable
      if (char_index[consonant,"position"] < vowels[1,"position"]) {
        syllabification[word,"\u03C3.1"] <- paste(c(as.character((char_index[,"segment"])[consonant]),
                                                    syllabification[word,"\u03C3.1"]),
                                                  collapse = "")
        # Indicate that it is now parsed and that it went into the first syllable
        char_index[consonant,"parsed"] <- TRUE
        char_index[consonant,"syllable"] <- "\u03C3.1"
      } else {
        # Otherwise, if the position of the unparsed consonant immediately precedes a vowel, parse it with that vowel
        if ((char_index[consonant,"position"]+1) %in% vowels$position) {
          syllabification[word,char_index[consonant+1,"syllable"]] <- paste(c(as.character(char_index[consonant,"segment"]),
                                                                              syllabification[word,char_index[consonant+1,"syllable"]]),
                                                                            collapse = "")
          # Indicate that it is now parsed and that it went into the syllable of the vowel that follows it
          char_index[consonant,"parsed"] <- TRUE
          char_index[consonant,"syllable"] <- char_index[consonant+1, "syllable"]
        } else {
          # Otherwise, if the position of the unparsed consonant does NOT immediately precede the end of the word, AND immediately precedes another consonant, ...
          # check if the string formed by pasting those two consonants together is in the list of licit onsets
          if (is.na(as.character(char_index[consonant+1, "segment"])) == FALSE){
            if (cvify(as.character(char_index[consonant+1,"segment"])) == "C") {
              # If those two characters pasted together is in the list of licit onsets, then parse the current consonant into the syllable of the following consonant
              if (paste(c(as.character(char_index[consonant, "segment"]),
                          as.character(char_index[consonant+1, "segment"])),
                        collapse = "") %in% onset_list) {
                syllabification[word,char_index[consonant+1,"syllable"]] <- paste(c(as.character(char_index[consonant,"segment"]),
                                                                                    syllabification[word,char_index[consonant+1,"syllable"]]),
                                                                                  collapse = "")
                # And mark that segment's parsed status as TRUE and indicate which syllable it was parsed into
                char_index[consonant,"parsed"] <- TRUE
                char_index[consonant,"syllable"] <- char_index[consonant+1, "syllable"]
              }
            }
          }
        }
      }
    }
    
    message("Step 2: Identify syllable onsets: ",
            paste(syllabification[,2:ncol(syllabification)],
                  collapse = ", "))
    
    ### Parse codas ###
    # For each unparsed consonant in the character index, starting from the beginning of the word, ...
    for (consonant in subset(char_index, parsed == FALSE)$position) {
      # Parse that consonant into the coda of the syllable into which the preceding segment was parsed
      syllabification[word, char_index[consonant-1,"syllable"]] <- paste(c(syllabification[word, char_index[consonant-1,"syllable"]],
                                                                           as.character(char_index[consonant,"segment"])),
                                                                         collapse = "")
      # And mark that segment's parsed status as TRUE and indicate which syllable it was parsed into
      char_index[consonant, "parsed"] <- TRUE
      char_index[consonant, "syllable"] <- char_index[consonant-1, "syllable"]
    }
    
    message("Step 3: Identify syllable codas: ",
            paste(syllabification[,2:ncol(syllabification)],
                  collapse = ", "))
  }
  # For each column in syllabification tbl, create collapsed version of syllabified word, using periods to separate syllables
#  for (word in nrow(syllabification)) {
#    for (syllable in )
#  }
  return(syllabification)
}
```

```{r syllabify_v0.3, options}
# Parse by indexing linear string, using sonority
# Parse stepwise by nucleus, onset, and coda; identifying dipththongs as a single nucleus
syllabify_v0.3 <- function(input, diphthong_list, onset_list, max_syll) {
  
  # Required packages
  require(stringr)
  
  # If no input specified, give a test example
  if (missing(input)) {
    input <- c("ðɪs", "ɪz", "ən", "əgzampəl")
  }
  
  # If diphthongs aren't specified, set it to American English diphthongs
  if (missing(diphthong_list)) {
    diphthong_list <- c("aɪ", "aʊ", "eɪ", "oʊ", "ɔɪ")
  }

  # If licit onsets not supplied, use this list
  if (missing(onset_list)) {
    onset_list <- c("ʃɹ", "ʃl", "ʃm", "ʃn", "ʃw", "θɹ", "bɹ", "bj", "bl", "bw", "dɹ", "dj", "dw", "fɹ", "fj", "fl", "gɹ", "gj", "gl", "gw", "hj", "hw", "kɹ", "kj", "kl", "kw", "mj", "pɹ", "pj", "pl", "sk", "sl", "sm", "sn", "sp", "st", "sv", "sw", "tɹ", "ts", "tw")
  }
  
  # Make a df to store syllabification info
  syllabification <- data.frame(NA)
  
  # Assign colnames
  colnames(syllabification) <- "input"
  
  # Give the df the unicode_df class so it's printed correctly
  class(syllabification) <- c("unicode_df", "data.frame")
  
  # Syllabify each word in the input, adding its information to each row
  for (word in 1:length(input)) {
    # Add the word to the df
    syllabification[word, 1] <- input[word]
    
    # Index ea segment by splitting word into component chars & associating ea w/ a # corresponding to its string-linear position
    split_word <- unlist(strsplit(as.character(input[word]), split = ""))
    char_index <- as.data.frame(as.matrix(split_word))
    class(char_index) <- c("unicode_df", "data.frame")
    colnames(char_index)[1] <- "segment"
    char_index[,"position"] <- 1:length(split_word)
    char_index[,"sonority"] <- sonority(split_word)
    char_index[,"parsed"] <- FALSE
    char_index[,"syllable"] <- 0
    
    ### Determine syllable nuclei ###
    # Extract vowels
    vowels <- subset(char_index, cvify(segment) == "V")
    
    # Get adjacent vowels (if there is more than one vowel in the word) & determine if they're diphthongs
    if (length(vowels$segment) > 1){
      ## Make a df to store each sequence of two vowels
      vowel_bigrams <- as.data.frame(matrix(ncol = 2))
      ## Set x to 1; each time the loop runs it will be increased by one so that the next bigram can be extracted
      x <- 1
      ## Get positions in linear string of original word of bigrams of extracted vowels
      for (vowel in 1:nrow(vowels)) {
        # If we didn't just parse the last vowel (if x is not equal to the number of vowels in the word), ...
        if (x != nrow(vowels)) {
          # ...then get the positions of those vowels and put in the vowel_bigram df
          vowel_bigrams[vowel,] <- vowels[x:(x+1), "position"]
          x <- x+1
        }
      }
      ## Get the diffs btw the pos'ns in the linear str to see which vowels were adjacent to each other in the original word
      vowel_bigrams$diff <- vowel_bigrams[,2] - vowel_bigrams[,1]
      ## If any vowels have a position difference of 1 (were actually adjacent to each other in the original string), subset only to them
      if (1 %in% vowel_bigrams$diff){
        ## Subset to originally adjacent vowels
        adjacent_vowels <- subset(vowel_bigrams, diff == 1)
		    class(adjacent_vowels) <- c("unicode_df", "data.frame")
        ## Extract the adjacent vowels using their positions & paste them together in a new column
        for (pair in 1:nrow(adjacent_vowels)) {
          adjacent_vowels[pair,"bigram"] <- paste(as.character(char_index[,"segment"][adjacent_vowels[pair,1]]),
                                                  as.character(char_index[,"segment"][adjacent_vowels[pair,2]]),
                                                  sep = "")
        }
        ## See if any of these bigrams match the known diphthongs & indicate in adjacent_vowels w/ TRUE or FALSE
        for (bigram in 1:nrow(adjacent_vowels)) {
          # If the bigram is in the list of diphthongs, mark it as TRUE
          if(adjacent_vowels[bigram,"bigram"] %in% diphthong_list){
            adjacent_vowels[bigram,"diphthong"] <- TRUE
          } else {
            # Otherwise, mark it as false
            adjacent_vowels[bigram,"diphthong"] <- FALSE
          }
        }
        # Save the bigrams that are recognized diphthongs if there are any
        if (TRUE %in% adjacent_vowels$diphthong){
          diphthongs <- droplevels(subset(adjacent_vowels, diphthong == TRUE))
		      class(diphthongs) <- c("unicode_df", "data.frame")
        }
      }
    }
    
    # Add column to vowel df that says whether the vowel is part of a diphthong (TRUE) or monophthong (FALSE), and if it is part of a diphthong, which diphthong it's a part of (by which row in the diphthongs df it's in)
    for (vowel in 1:nrow(vowels)) {
      if (exists("diphthongs")) {
        if (vowels$position[vowel] %in% as.character(as.matrix(diphthongs[,1:2]))) {
        vowels[vowel,"in.diphthong"] <- TRUE
        vowels[vowel,"which.diphthong"] <- row(diphthongs[,1:2])[which(diphthongs[,1:2] == vowels$position[vowel])]
        } else {
          vowels[vowel,"in.diphthong"] <- FALSE
          # If the vowel isn't part of a diphthong, set "which.diphthong" to 0. Anything that's an actual diphthong will never be assigned zero since row numbers (in the diphthongs df) start w/ 1. Needs to be 0 b/c otherwise it's NA, in which case an error is returned when testing if two vowel characters are part of the same diphthong.
          vowels[vowel,"which.diphthong"] <- 0
        }
      } else {
        vowels[vowel,"in.diphthong"] <- FALSE
        # If the vowel isn't part of a diphthong, set "which.diphthong" to 0. Anything that's an actual diphthong will never be assigned zero since row numbers (in the diphthongs df) start w/ 1. Needs to be 0 b/c otherwise it's NA, in which case an error is returned when testing if two vowel characters are part of the same diphthong.
        vowels[vowel,"which.diphthong"] <- 0
      }
    }
    
    # We now have enough information to say which vowel segments are associated w/ which syllables
    # Cycle through the vowel df and create a vector for the syllable nuclei in this word
    nuclei <- NA
    x <- 1
    for (vowel in 1:nrow(vowels)) {
      # If the vowel is not part of a diphthong, add it to the list of nuclei
      if (vowels[vowel,"in.diphthong"] == FALSE) {
        nuclei[x] <- as.character(vowels[vowel,"segment"])
        # Change parsed status to TRUE
        char_index[vowels[vowel,"position"],]$parsed <- TRUE
        # Indicate which syllable this vowel was parsed into
        char_index[vowels[vowel,"position"],]$syllable <- paste(c("\u03C3.", x), collapse = "")
        # Add one to the syllable counter
        x <- x+1
      } else {
        # If we're not at the last vowel in vowels and the vowel and the following vowel are part of a diphthong together, paste them together as the next nucleus
        if (vowel != nrow(vowels)) {
          if (vowels[vowel,"which.diphthong"] > 0 & vowels[vowel,"which.diphthong"] == vowels[vowel+1,"which.diphthong"]) {
          nuclei[x] <- paste(as.character(vowels[vowel:(vowel+1),"segment"]), collapse = "")
          # Change parsed status for both vowels to TRUE
          char_index[vowels[vowel,"position"],]$parsed <- TRUE
          char_index[vowels[vowel,"position"]+1,]$parsed <- TRUE
          # Indicate which syllable this vowel and the following vowel was parsed into
          char_index[vowels[vowel,"position"],]$syllable <- paste(c("\u03C3.", x), collapse = "")
          char_index[vowels[vowel,"position"]+1,]$syllable <- paste(c("\u03C3.", x), collapse = "")
          x <- x+1
        }
        }
      }
    }
    
    # Add nuclei to syllabification table for current word
    for (nucleus in 1:length(nuclei)) {
      syllabification[word,paste(c("\u03C3", nucleus), collapse = ".")] <- as.character(nuclei[nucleus])
    }
    
    # Remove vowel-related objects (IMPORTANT; this can screw up the next word if more than one word is supplied to the function)
    if (exists("vowel_bigrams")) {
      rm(vowel_bigrams)
    }
    if (exists("adjacent_vowels")) {
      rm(adjacent_vowels)
    }
    if (exists("diphthongs")){
      rm(diphthongs)
    }
    
    
    
    ### Parse onsets ###
    # For each unparsed consonant in the character index, starting from the end of the word, ...
    for (consonant in rev(subset(char_index, parsed == FALSE)$position)) {
      # If the consonant is preceding the first vowel, parse it into the first syllable
      if (char_index[consonant,"position"] < vowels[1,"position"]) {
        syllabification[word,"\u03C3.1"] <- paste(c(as.character((char_index[,"segment"])[consonant]),
                                                    syllabification[word,"\u03C3.1"]),
                                                  collapse = "")
        # Indicate that it is now parsed and that it went into the first syllable
        char_index[consonant,"parsed"] <- TRUE
        char_index[consonant,"syllable"] <- "\u03C3.1"
      } else {
        # Otherwise, if the position of the unparsed consonant immediately precedes a vowel, parse it with that vowel
        if ((char_index[consonant,"position"]+1) %in% vowels$position) {
          syllabification[word,char_index[consonant+1,"syllable"]] <- paste(c(as.character(char_index[consonant,"segment"]),
                                                                              syllabification[word,char_index[consonant+1,"syllable"]]),
                                                                            collapse = "")
          # Indicate that it is now parsed and that it went into the syllable of the vowel that follows it
          char_index[consonant,"parsed"] <- TRUE
          char_index[consonant,"syllable"] <- char_index[consonant+1, "syllable"]
        } else {
          # Otherwise, if the position of the unparsed consonant does NOT immediately precede the end of the word, AND immediately precedes another consonant, check if the string formed by pasting those two consonants together is in the list of licit onsets
          if (is.na(as.character(char_index[consonant+1, "segment"])) == FALSE){
            if (cvify(as.character(char_index[consonant+1,"segment"])) == "C") {
              # If those two characters pasted together is in the list of licit onsets, then parse the current consonant into the syllable of the following consonant
              if (paste(c(as.character(char_index[consonant, "segment"]), as.character(char_index[consonant+1, "segment"])), collapse = "") %in% onset_list) {
                syllabification[word,char_index[consonant+1,"syllable"]] <- paste(c(as.character(char_index[consonant,"segment"]),
                                                                                    syllabification[word,char_index[consonant+1,"syllable"]]),
                                                                                  collapse = "")
                # And mark that segment's parsed status as TRUE and indicate which syllable it was parsed into
                char_index[consonant,"parsed"] <- TRUE
                char_index[consonant,"syllable"] <- char_index[consonant+1, "syllable"]
              }
            }
          }
        }
      }
    }
    
    
    ### Parse codas ###
    # For each unparsed consonant in the character index, starting from the beginning of the word, ...
    for (consonant in subset(char_index, parsed == FALSE)$position) {
      # Parse that consonant into the coda of the syllable into which the preceding segment was parsed
      syllabification[word, char_index[consonant-1,"syllable"]] <- paste(c(syllabification[word, char_index[consonant-1,"syllable"]],
                                                                           as.character(char_index[consonant,"segment"])),
                                                                         collapse = "")
      # And mark that segment's parsed status as TRUE and indicate which syllable it was parsed into
      char_index[consonant, "parsed"] <- TRUE
      char_index[consonant, "syllable"] <- char_index[consonant-1, "syllable"]
    }
  }
  # For each column in syllabification tbl, create collapsed version of syllabified word, using periods to separate syllables
#  for (word in nrow(syllabification)) {
#    for (syllable in )
#  }
  return(syllabification)
}
```